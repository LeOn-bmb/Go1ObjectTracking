Introduction
---

Dieses Projekt baut auf dem Unitree Camera SDK auf, das unter der Mozilla Public License 2.0 verÃ¶ffentlicht wurde. Der vorhandene Quellcode wurde erweitert und angepasst, um neue FunktionalitÃ¤ten zu realisieren.

Ziel dieses Projekts ist es, den Go1-Roboter von Unitree mit einem Echtzeit-Objekterkennungs- und Verfolgungssystem auszustatten. Dabei erkennt der Roboter bestimmte Objekte (z.B. Flaschen), bestimmt ihre Entfernung mittels aktiver Stereovision und steuert anschlieÃŸend auf das nÃ¤chste Ziel zu, bis ein definierter Sicherheitsabstand erreicht ist. Dieser Abstand wird dann dynamisch gehalten.

ğŸ§­ 1. Overview
---

Dieses Verzeichnis stellt den vollstÃ¤ndigen Software-Stack zur VerfÃ¼gung, um den Go1-Roboter fÃ¼r folgende Aufgaben vorzubereiten:

- Objekterkennung mittels YOLO11n-Engine-Model (Inference optimiert mit TensorRT fÃ¼r maximale Performance auf Jetson-Plattformen)
- Tiefenmessung via Depth-Frames aus der Unitree Kamera (ermÃ¶glicht prÃ¤zise Distanzberechnungen zu erkannten Objekten)
- Zielverfolgung durch Navigation bis zum Objekt mit aktivem Abstandsregler
- Modulare Architektur mit ZeroMQ fÃ¼r die BildÃ¼bertragung zwischen Kamera-Head (Jetson Nano) und Verarbeitungseinheit (Xavier NX)

Das System wurde fÃ¼r ressourcenbeschrÃ¤nkte Edge-Hardware wie den Jetson Xavier NX optimiert und unterstÃ¼tzt optimierte Objekterkennungs-Modelle Ã¼ber TensorRT. Shape (width, height) nah an RectFrame-Size der Go1 Kamera angepasst und YOLO-Kompatibel (teilbar durch 32).

ğŸ”§ 2. Build-Time Dependencies (fÃ¼r Modellkonvertierung auf Host/XavierNX, Python 3.8)
---

- [Python3.8 oder hÃ¶her](https://linuxize.com/post/how-to-install-python-3-8-on-ubuntu-18-04/) - erforderlich fÃ¼r ultralytics
- [Ultralytics](https://docs.ultralytics.com/de/quickstart/) - zum Laden und Exportieren von YOLO .pt-Modellen in .onnx
- [PyTorch](https://docs.ultralytics.com/de/guides/nvidia-jetson/#install-pytorch-and-torchvision) â€“ automatisch mit ultralytics installiert (nur kompatibel mit x86 / nicht direkt auf Jetson)
- ONNX, ONNX-Simplifier â€“ fÃ¼r ONNX-Export, falls simplify=True
- trtexec - CLI-Tool aus dem NVIDIA TensorRT Toolkit (wandelt .onnx â†’ .engine um; befindet sich i.â€¯d.â€¯R. unter /usr/src/tensorrt/bin/trtexec)

ğŸš€ 2.1 Runtime Dependencies (auf Jetson Go1, Python 3.6)
---

- OpenCV (Version 4 oder hÃ¶her) - fÃ¼r Bildverarbeitung
- CMake (Version 3.11 oder hÃ¶her) - zum bauen von C-Anwendungen
- Python3 (Version 3.6 oder hÃ¶her)
- [ZeroMQ](https://zeromq.org/get-started/) - leichtgewichtige Messaging-Library (fÃ¼r Bildstreaming vom Jetson Nano zum Xavier NX)
  
Nur auf Xavier NX erforderlich fÃ¼r Objekterkennung
---

- [TensorRT](https://developer.nvidia.com/tensorrt) - NVIDIA-Inferenz-Bibliothek, die speziell fÃ¼r NVIDIA GPUs die maximale Inferenz-Performance aus ONNX-Modellen herausholt (z.â€¯B. Version 7.1.3.0 unter JetPack 4.5)
- [PyCUDA](https://wiki.tiker.net/PyCuda/Installation/Linux/) â€“ nÃ¼tzlich fÃ¼r Memory Binding, CUDA Streams mit TensorRT & Speicherverwaltung in GPU

ğŸ“ 3. Build 
---

ğŸ”¨ Bauen der C++-Anwendung auf dem Jetson Nano
```
cd Go1ObjectTracking;
mkdir build && cd build;
cmake ..;
make
```

ğŸš€ 4. Run 
---

ğŸ¥ Stereo-Kameras auf dem nano head auf blockierende Prozesse Ã¼berprÃ¼fen:
```
v4l2-ctl --list-devices;
lsof /dev/video1;
kill -9 <PID>   # falls erforderlich
```

ğŸ“¤ Senden der Frames an den Jetson Xavier NX:
```
cd Go1ObjectTracking; 
./bin/send_perception
```

ğŸ Hauptprogramm auf dem Xavier NX starten:
```
cd Go1ObjectTracking/src/XavierNX; 
python3 main.py
```